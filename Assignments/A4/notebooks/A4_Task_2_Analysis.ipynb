{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigation into the results\n",
    "\n",
    "Let's see where exactly our models succeeded and failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = pd.read_csv('/home/snow/NEU/CS6120/Assignments/A4/data/model_1.csv')\n",
    "result_2 = pd.read_csv('/home/snow/NEU/CS6120/Assignments/A4/data/model_2.csv')\n",
    "result_3 = pd.read_csv('/home/snow/NEU/CS6120/Assignments/A4/data/model_3.csv')\n",
    "review_set = pd.read_csv('/home/snow/NEU/CS6120/Assignments/A4/data/review_set_latest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1.rename(columns={'sentiment_analysis': 'sentiment_analysis_1'}, inplace=True)\n",
    "result_2.rename(columns={'sentiment_analysis': 'sentiment_analysis_2'}, inplace=True)\n",
    "result_3.rename(columns={'sentiment_analysis': 'sentiment_analysis_3'}, inplace=True)\n",
    "review_set.rename(columns={'sentiment': 'ground_truth_sentiment'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([result_1, result_2, result_3, review_set], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "We used the following models (fetched from huggingface):\n",
    "<br><br>\n",
    "model_1 = 'distilbert-base-uncased-finetuned-sst-2-english' (Result_1)<br>\n",
    "model_2 = 'cardiffnlp/twitter-roberta-base-sentiment-latest' (Result_2)<br>\n",
    "model_3 = 'siebert/sentiment-roberta-large-english' (Result_3)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "model_2 = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "model_3 = 'siebert/sentiment-roberta-large-english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_analysis_1</th>\n",
       "      <th>sentiment_analysis_2</th>\n",
       "      <th>sentiment_analysis_3</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>possible cigar shop even less friendly fair oa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>positive</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>3</td>\n",
       "      <td>one favourite spots tempe offers eclectic iris...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>positive</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>new mexico thought id go amazing green red chi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>positive</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>3</td>\n",
       "      <td>food awesome drinks kind watered sitting outsi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>positive</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>4</td>\n",
       "      <td>bourbon great place enjoy brunch crazy nights ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>let sum sweet cakes two words rated my wife lo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>of as exist less a blocks apartment would neve...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>know seen place showcased food network a times...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>understand hype lamb linda loo meh meat potato...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>ordered a fried tacos filling little bland fir...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment_analysis_1 sentiment_analysis_2 sentiment_analysis_3  label  \\\n",
       "0                  NEGATIVE              neutral             NEGATIVE      1   \n",
       "1                  POSITIVE             positive             POSITIVE      3   \n",
       "2                  NEGATIVE             positive             NEGATIVE      0   \n",
       "3                  POSITIVE             positive             POSITIVE      3   \n",
       "4                  POSITIVE             positive             POSITIVE      4   \n",
       "...                     ...                  ...                  ...    ...   \n",
       "199995                  NaN                  NaN                  NaN      1   \n",
       "199996                  NaN                  NaN                  NaN      1   \n",
       "199997                  NaN                  NaN                  NaN      1   \n",
       "199998                  NaN                  NaN                  NaN      1   \n",
       "199999                  NaN                  NaN                  NaN      1   \n",
       "\n",
       "                                                     text  \\\n",
       "0       possible cigar shop even less friendly fair oa...   \n",
       "1       one favourite spots tempe offers eclectic iris...   \n",
       "2       new mexico thought id go amazing green red chi...   \n",
       "3       food awesome drinks kind watered sitting outsi...   \n",
       "4       bourbon great place enjoy brunch crazy nights ...   \n",
       "...                                                   ...   \n",
       "199995  let sum sweet cakes two words rated my wife lo...   \n",
       "199996  of as exist less a blocks apartment would neve...   \n",
       "199997  know seen place showcased food network a times...   \n",
       "199998  understand hype lamb linda loo meh meat potato...   \n",
       "199999  ordered a fried tacos filling little bland fir...   \n",
       "\n",
       "       ground_truth_sentiment  \n",
       "0                    negative  \n",
       "1                    positive  \n",
       "2                    negative  \n",
       "3                    positive  \n",
       "4                    positive  \n",
       "...                       ...  \n",
       "199995               negative  \n",
       "199996               negative  \n",
       "199997               negative  \n",
       "199998               negative  \n",
       "199999               negative  \n",
       "\n",
       "[200000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimming to make sure only the columns we experimented on are retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['sentiment_analysis_1'] = combined['sentiment_analysis_1'].str.lower()\n",
    "combined['sentiment_analysis_2'] = combined['sentiment_analysis_2'].str.lower()\n",
    "combined['sentiment_analysis_3'] = combined['sentiment_analysis_3'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's assume that neutral corresponds to negative in the second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['sentiment_analysis_2'] = combined['sentiment_analysis_2'].replace('neutral', 'negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first calculate the accuracy of each model to get an initial sembalance of how \"accurate\" they might be for this use case\n",
    "\n",
    "<br>\n",
    "\n",
    "First, Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.99047923833906"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_model_1 = (combined['sentiment_analysis_1'] == combined['ground_truth_sentiment']).mean() * 100\n",
    "accuracy_model_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It still leaves 20% of the cases, interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50355/4026146000.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  incorrect_1.drop(columns=['sentiment_analysis_2', 'sentiment_analysis_3'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "incorrect_1 = combined[combined['sentiment_analysis_1'] != combined['ground_truth_sentiment']]\n",
    "incorrect_1.drop(columns=['sentiment_analysis_2', 'sentiment_analysis_3'], axis=1, inplace=True)\n",
    "incorrect_1 = incorrect_1.reindex(columns=['label','text', 'ground_truth_sentiment', 'sentiment_analysis_1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth_sentiment</th>\n",
       "      <th>sentiment_analysis_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>first good where began cannot begin known know...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>first trip wildlife world zoo great like dirt ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>place truly gem east valley first cheaper chea...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>writing first review customer service manageme...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>decided pay homage faux jewish tradition chine...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49987</th>\n",
       "      <td>4</td>\n",
       "      <td>want live restaurants i posted go robot headin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49988</th>\n",
       "      <td>1</td>\n",
       "      <td>something old spaghetti factory love really li...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49991</th>\n",
       "      <td>3</td>\n",
       "      <td>wife twice last two weeks four times together ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49994</th>\n",
       "      <td>3</td>\n",
       "      <td>hearing place endorsed oprah friend gale best ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>4</td>\n",
       "      <td>wait staff friendly quick keep drink refilled ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9504 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "12         0  first good where began cannot begin known know...   \n",
       "26         4  first trip wildlife world zoo great like dirt ...   \n",
       "31         4  place truly gem east valley first cheaper chea...   \n",
       "42         3  writing first review customer service manageme...   \n",
       "45         1  decided pay homage faux jewish tradition chine...   \n",
       "...      ...                                                ...   \n",
       "49987      4  want live restaurants i posted go robot headin...   \n",
       "49988      1  something old spaghetti factory love really li...   \n",
       "49991      3  wife twice last two weeks four times together ...   \n",
       "49994      3  hearing place endorsed oprah friend gale best ...   \n",
       "49999      4  wait staff friendly quick keep drink refilled ...   \n",
       "\n",
       "      ground_truth_sentiment sentiment_analysis_1  \n",
       "12                  negative             positive  \n",
       "26                  positive             negative  \n",
       "31                  positive             negative  \n",
       "42                  positive             negative  \n",
       "45                  negative             positive  \n",
       "...                      ...                  ...  \n",
       "49987               positive             negative  \n",
       "49988               negative             positive  \n",
       "49991               positive             negative  \n",
       "49994               positive             negative  \n",
       "49999               positive             negative  \n",
       "\n",
       "[9504 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at various outputs where the model went wrong here.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth_sentiment</th>\n",
       "      <th>sentiment_analysis_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35533</th>\n",
       "      <td>4</td>\n",
       "      <td>love place never bad experience times one gree...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22539</th>\n",
       "      <td>3</td>\n",
       "      <td>wait reviewed crepes parisian penni first fell...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328</th>\n",
       "      <td>1</td>\n",
       "      <td>international hub airport regional airport fee...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44001</th>\n",
       "      <td>1</td>\n",
       "      <td>atmosphere really nice server took forever kno...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22489</th>\n",
       "      <td>3</td>\n",
       "      <td>landed vegas picked friend taken dinner eat su...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "35533      4  love place never bad experience times one gree...   \n",
       "22539      3  wait reviewed crepes parisian penni first fell...   \n",
       "7328       1  international hub airport regional airport fee...   \n",
       "44001      1  atmosphere really nice server took forever kno...   \n",
       "22489      3  landed vegas picked friend taken dinner eat su...   \n",
       "\n",
       "      ground_truth_sentiment sentiment_analysis_1  \n",
       "35533               positive             negative  \n",
       "22539               positive             negative  \n",
       "7328                negative             positive  \n",
       "44001               negative             positive  \n",
       "22489               positive             negative  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_1.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love place never bad experience times one green valley freshly squeezed juices amazing especially watermelon favourite one funny thing place apparently difference breakfast burrito breakfast wrap bacon lovers get wrap burrito kind slaughters animal'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_1.text[35533]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see although this is describing something in irony, the model only looks at words like \"bad experience\".\n",
    "\n",
    "\n",
    "Let's try looking at the attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snow/miniconda3/envs/CS6120/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "def get_top_attended_words(sentence, model_name, top_n=3):\n",
    "    \"\"\"\n",
    "    Returns the top `top_n` words with the highest attention scores for a given sentence\n",
    "    using a pre-trained transformer model from Hugging Face.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence.\n",
    "        model_name (str): The name of the pre-trained Hugging Face model to use.\n",
    "        top_n (int, optional): The number of top attended words to return. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples containing the top attended words and their attention scores.\n",
    "    \"\"\"\n",
    "    # Load the pre-trained model and tokenizer\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize the input sentence\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "    # Get the attention scores from the model\n",
    "    outputs = model(**inputs, output_attentions=True)\n",
    "    attention_scores = outputs.attentions\n",
    "\n",
    "    # Decode the input token IDs\n",
    "    input_ids = inputs.input_ids.squeeze().tolist()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # Compute the average attention score for each word across all heads and layers\n",
    "    word_scores = []\n",
    "    for token_idx, token in enumerate(tokens):\n",
    "        if token not in tokenizer.all_special_tokens:\n",
    "            avg_score = 0\n",
    "            for layer in attention_scores:\n",
    "                attention_matrix = layer.squeeze(0)\n",
    "                for head in range(attention_matrix.size(0)):\n",
    "                    avg_score += attention_matrix[head, token_idx, token_idx].item()\n",
    "            avg_score /= (len(attention_scores) * attention_matrix.size(0))\n",
    "            word_scores.append((token, avg_score))\n",
    "\n",
    "    # Sort the words by their attention scores in descending order\n",
    "    word_scores = sorted(word_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return the top `top_n` attended words and their scores\n",
    "    return word_scores[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('never', 0.12569126340819123),\n",
       " ('lovers', 0.11829061958990057),\n",
       " ('difference', 0.1083284916570043),\n",
       " ('green', 0.1073714267761151),\n",
       " ('times', 0.10689252069211802),\n",
       " ('bad', 0.1054180827335735),\n",
       " ('favourite', 0.10424478334484395),\n",
       " ('apparently', 0.09845863395158415),\n",
       " ('amazing', 0.09692895958028834),\n",
       " ('experience', 0.09688492519484725)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_attended_words(incorrect_1.text[35533], 'nlptown/bert-base-multilingual-uncased-sentiment', top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the word \"never\" and bad\" which may be negative words probably affect this\n",
    "\n",
    "\n",
    "Let's look at other examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wait reviewed crepes parisian penni first fell love crepes early teenage years crepe shop opened hometown state college yes town best known love football binge drinking restaurant sold crepes practically transcendent stuffed anything could imagine surprisingly last long heart broke closed could get crepe fix yearly family vacations disney world in sophomore year college studied abroad italy rediscovered crepe obsession found british style pub trip paris four days eating simple street version day breakfast returned state college crepe less sad excited moved pittsburgh found crepes paris ennis even think need answer questions these good crepes perfectly crispy outside soft inside topping list unfortunately limited many veggies one type cheese bacon breakfast crepe strawberries dessert crepe still cannot really go wrong combinations in came back state college tried new crepe shop town sucked made realize totally take crepes paris ennis granted food might simple trust say pittsburgh lucky'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_1.text[22539]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This specific review has a really long length. Maybe the incorrect assumption is tied to the token length of the sentence going beyond the context length of the model?\n",
    "\n",
    "<br>\n",
    "\n",
    "Anyway, we can see that there's some negative words here like \"wrong\", \"cannot\" and \"heart broke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('many', 0.11025072930876728),\n",
       " ('less', 0.10924100640737915),\n",
       " ('sold', 0.1091226130129119),\n",
       " ('answer', 0.10675539588333818),\n",
       " ('cannot', 0.09768045302673808),\n",
       " ('questions', 0.09531632989643071),\n",
       " ('style', 0.09409198279839244),\n",
       " ('limited', 0.09360749617315424),\n",
       " ('need', 0.09037736056553787),\n",
       " ('last', 0.089730187899381)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_attended_words(incorrect_1.text[22539], 'nlptown/bert-base-multilingual-uncased-sentiment', top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do see that a lot of words like \"less\", \"cannot\" and \"limited\" might connotate to negative sentiment.\n",
    "\n",
    "The more so neutral words like \"sold\" and \"answer\" may also slightly connotate towards that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one more last example before analysing the role of context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'atmosphere really nice server took forever know many tables service slow food bland overall tasteless many better alternatives phoenix area waste time'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_1.text[44001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we directly start with some really positive words but the review becomes more negative later on.\n",
    "\n",
    "Let's see what the model decided to focus on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('atmosphere', 0.1389096469846583),\n",
       " ('know', 0.12247882523831836),\n",
       " ('phoenix', 0.1095007317115441),\n",
       " ('tables', 0.09957821914220037),\n",
       " ('server', 0.09844110710409718),\n",
       " ('service', 0.09725036371750918),\n",
       " ('##less', 0.0948395630559057),\n",
       " ('bland', 0.09448296326911168),\n",
       " ('really', 0.09295481919571039),\n",
       " ('many', 0.0917020695467984)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_attended_words(incorrect_1.text[44001], 'nlptown/bert-base-multilingual-uncased-sentiment', top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, it did focus on atmosphere the most. But it also focuses a lot on pheonix, which is a city. Will it change the review if we remove the top 5 attention score words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9958256483078003}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_pipeline_1 = pipeline(model=\"distilbert-base-uncased-finetuned-sst-2-english\", task=\"sentiment-analysis\")\n",
    "\n",
    "print(model_pipeline_1('really nice took forever many service slow food bland overall tasteless many better alternatives area waste time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does become negative! Let's look at the attention scores now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nice', 0.1271290696051829),\n",
       " ('service', 0.08754791983805009),\n",
       " ('bland', 0.08537290109112898),\n",
       " ('alternatives', 0.08195795190598412),\n",
       " ('took', 0.0702056008118682),\n",
       " ('many', 0.06820320562748192),\n",
       " ('really', 0.06695909363165373),\n",
       " ('area', 0.059745954109471665),\n",
       " ('waste', 0.058999269110081944),\n",
       " ('food', 0.05485497491754285)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_attended_words('really nice took forever many service slow food bland overall tasteless many better alternatives area waste time', 'distilbert-base-uncased-finetuned-sst-2-english', top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a lot of negative words are in the top 10 attended words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def get_token_length(sentence, model_name):\n",
    "    \"\"\"\n",
    "    Returns the length of the tokenized sentence using a pre-trained transformer model\n",
    "    from Hugging Face.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence.\n",
    "        model_name (str): The name of the pre-trained Hugging Face model to use.\n",
    "\n",
    "    Returns:\n",
    "        int: The length of the tokenized sentence.\n",
    "    \"\"\"\n",
    "    # Load the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize the input sentence\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "\n",
    "    # Return the length of the tokenized sentence\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the reviews by number of words first since more words = more tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_1_sorted = incorrect_1.assign(num_words=incorrect_1['text'].str.split().str.len()).sort_values('num_words', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth_sentiment</th>\n",
       "      <th>sentiment_analysis_1</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>4</td>\n",
       "      <td>like people visit las vegas found high meth st...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46276</th>\n",
       "      <td>0</td>\n",
       "      <td>beginning a days las vegas soon arrived starte...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35240</th>\n",
       "      <td>3</td>\n",
       "      <td>sonnets done completed a days friday pretty go...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49607</th>\n",
       "      <td>0</td>\n",
       "      <td>watching top chef already michael volt agios s...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39447</th>\n",
       "      <td>3</td>\n",
       "      <td>great hotel price get cheap deals good rates o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34379</th>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34642</th>\n",
       "      <td>1</td>\n",
       "      <td>fast</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36321</th>\n",
       "      <td>0</td>\n",
       "      <td>serve</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15566</th>\n",
       "      <td>1</td>\n",
       "      <td>comment</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21533</th>\n",
       "      <td>1</td>\n",
       "      <td>better</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9504 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "4777       4  like people visit las vegas found high meth st...   \n",
       "46276      0  beginning a days las vegas soon arrived starte...   \n",
       "35240      3  sonnets done completed a days friday pretty go...   \n",
       "49607      0  watching top chef already michael volt agios s...   \n",
       "39447      3  great hotel price get cheap deals good rates o...   \n",
       "...      ...                                                ...   \n",
       "34379      0                                               good   \n",
       "34642      1                                               fast   \n",
       "36321      0                                              serve   \n",
       "15566      1                                            comment   \n",
       "21533      1                                             better   \n",
       "\n",
       "      ground_truth_sentiment sentiment_analysis_1  num_words  \n",
       "4777                positive             negative        504  \n",
       "46276               negative             positive        495  \n",
       "35240               positive             negative        494  \n",
       "49607               negative             positive        493  \n",
       "39447               positive             negative        492  \n",
       "...                      ...                  ...        ...  \n",
       "34379               negative             positive          1  \n",
       "34642               negative             positive          1  \n",
       "36321               negative             positive          1  \n",
       "15566               negative             positive          1  \n",
       "21533               negative             positive          1  \n",
       "\n",
       "[9504 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_1_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly for this case, all the reviews are under the context length.\n",
    "\n",
    "Let's move on to model 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.04464357148572"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_model_2 = (combined['sentiment_analysis_2'] == combined['ground_truth_sentiment']).mean() * 100\n",
    "accuracy_model_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model scores higher than the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50355/1819985054.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  incorrect_2.drop(columns=['sentiment_analysis_1', 'sentiment_analysis_3'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "incorrect_2 = combined[combined['sentiment_analysis_2'] != combined['ground_truth_sentiment']]\n",
    "incorrect_2.drop(columns=['sentiment_analysis_1', 'sentiment_analysis_3'], axis=1, inplace=True)\n",
    "incorrect_2 = incorrect_2.reindex(columns=['label','text', 'ground_truth_sentiment', 'sentiment_analysis_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth_sentiment</th>\n",
       "      <th>sentiment_analysis_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>new mexico thought id go amazing green red chi...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>recent trip vegas girlfriend decided stop quic...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>first good where began cannot begin known know...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>customer service best neither bagels no bagels...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>tried havana cafe several times love cuban foo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49976</th>\n",
       "      <td>1</td>\n",
       "      <td>reservation made recommendation concierge new ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49981</th>\n",
       "      <td>1</td>\n",
       "      <td>course overly impressed quality actual course ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49984</th>\n",
       "      <td>1</td>\n",
       "      <td>salon star rating based salon my friend gift c...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49988</th>\n",
       "      <td>1</td>\n",
       "      <td>something old spaghetti factory love really li...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49991</th>\n",
       "      <td>3</td>\n",
       "      <td>wife twice last two weeks four times together ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8477 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "2          0  new mexico thought id go amazing green red chi...   \n",
       "11         1  recent trip vegas girlfriend decided stop quic...   \n",
       "12         0  first good where began cannot begin known know...   \n",
       "15         1  customer service best neither bagels no bagels...   \n",
       "16         1  tried havana cafe several times love cuban foo...   \n",
       "...      ...                                                ...   \n",
       "49976      1  reservation made recommendation concierge new ...   \n",
       "49981      1  course overly impressed quality actual course ...   \n",
       "49984      1  salon star rating based salon my friend gift c...   \n",
       "49988      1  something old spaghetti factory love really li...   \n",
       "49991      3  wife twice last two weeks four times together ...   \n",
       "\n",
       "      ground_truth_sentiment sentiment_analysis_2  \n",
       "2                   negative             positive  \n",
       "11                  negative             positive  \n",
       "12                  negative             positive  \n",
       "15                  negative             positive  \n",
       "16                  negative             positive  \n",
       "...                      ...                  ...  \n",
       "49976               negative             positive  \n",
       "49981               negative             positive  \n",
       "49984               negative             positive  \n",
       "49988               negative             positive  \n",
       "49991               positive             negative  \n",
       "\n",
       "[8477 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right off the bat we can see that a lot of these reviews are actually negative in ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ground_truth_sentiment\n",
       "negative    5241\n",
       "positive    3236\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_2.ground_truth_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do have more negative reviews than positive ones, but not by a very large margin. \n",
    "\n",
    "Let's look at the negative reviews first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth_sentiment</th>\n",
       "      <th>sentiment_analysis_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35145</th>\n",
       "      <td>1</td>\n",
       "      <td>better yams mac a cheese chicken waffles good ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27129</th>\n",
       "      <td>1</td>\n",
       "      <td>went sunday usually go chain restaurants simpl...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48751</th>\n",
       "      <td>4</td>\n",
       "      <td>id always gone tempe location one day drove on...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45272</th>\n",
       "      <td>1</td>\n",
       "      <td>located inconspicuous office park summer in vi...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44712</th>\n",
       "      <td>1</td>\n",
       "      <td>worse better remember coming hotel new excitin...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "35145      1  better yams mac a cheese chicken waffles good ...   \n",
       "27129      1  went sunday usually go chain restaurants simpl...   \n",
       "48751      4  id always gone tempe location one day drove on...   \n",
       "45272      1  located inconspicuous office park summer in vi...   \n",
       "44712      1  worse better remember coming hotel new excitin...   \n",
       "\n",
       "      ground_truth_sentiment sentiment_analysis_2  \n",
       "35145               negative             positive  \n",
       "27129               negative             positive  \n",
       "48751               positive             negative  \n",
       "45272               negative             positive  \n",
       "44712               negative             positive  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'better yams mac a cheese chicken waffles good think change taste burn sugars'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_2.text[35145]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, that does not look like a negative review at first sight at all. Perhaps stopword removal is a reason?\n",
    "\n",
    "Let's look at the attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Ä burn', 0.12429455186672082),\n",
       " ('Ä taste', 0.11256080750536215),\n",
       " ('Ä change', 0.08949126762571621),\n",
       " ('better', 0.08711572451654356),\n",
       " ('Ä good', 0.08327986972418937),\n",
       " ('Ä sugars', 0.08302358181691519),\n",
       " ('Ä chicken', 0.07897849968250942),\n",
       " ('Ä think', 0.07223392039142912),\n",
       " ('Ä w', 0.06453572549630987),\n",
       " ('Ä mac', 0.06351876395081035)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_attended_words(incorrect_2.text[35145], model_2, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly we see that a lot of words are actually positive, like good, sugar. Perhaps the names of food are also positive? \n",
    "\n",
    "Let's look at other examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'went sunday usually go chain restaurants simply many delicious locally owned restaurants area however gift card decided go dinner new got around a wait table however left lot people lobby waiting seat new ordered glass house red well priced good house wine in ordered soup salad pasta ago i soup husband ordered lasagna primavera lighter side part menu spinach veggies in breadsticks salad came like expected breadsticks always relish hard turn away eating soup good husbands lasagna even better however joking wonder lasagna lighter side small guess expected given making lasagna light easy task cannot even begin explain small was and normally normally split meals restaurants typically used smaller portions begin probably size half deck cards width length height like a small pieces grilled chicken ate complaint tasty though normally skip dessert waitress came husband ordered pumpkin cheesecake sure still hungry craving something sweet good huge slice cheesecake tasty slice gone like a minutes hama overall of experience would go back unless another gift card'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_2.text[27129]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yet again is an interesting example. This specific review is longer than the previous one yet also does not focus more on the \"bad\" part of the review, but actually wants to tell a story. This means a large section of the review starts with a good experience and generally positive words like \"many delicious\" and \"gift card\"\n",
    "\n",
    "<br>\n",
    "Let's look at the top attended words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('went', 0.08571032425975739),\n",
       " ('Ä typically', 0.078513232757435),\n",
       " ('Ä restaurants', 0.07422453045531559),\n",
       " ('Ä width', 0.07202442480284946),\n",
       " ('Ä waitress', 0.0705371983363471),\n",
       " ('Ä cannot', 0.06554504361397465),\n",
       " ('Ä spinach', 0.06439080891383735),\n",
       " ('Ä length', 0.06430681773518801),\n",
       " ('Ä husband', 0.06378154147668941),\n",
       " ('Ä many', 0.0628289932149831),\n",
       " ('Ä delicious', 0.06271431964261057),\n",
       " ('Ä expected', 0.0626416168878576),\n",
       " ('Ä tasty', 0.061730227594658044),\n",
       " ('Ä husband', 0.06043951710125839),\n",
       " ('Ä tasty', 0.059901138705779684),\n",
       " ('Ä would', 0.05981449450669629),\n",
       " ('Ä small', 0.05837876797748246),\n",
       " ('Ä go', 0.057640770086682856),\n",
       " ('Ä light', 0.057113586400895935),\n",
       " ('Ä always', 0.05584949157325051)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_attended_words(incorrect_2.text[27129], model_2, top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very interesting, we see that the top words do have generally positive words but a lot of them are neutral words as well.\n",
    "\n",
    "Perhaps this was a neutral review that converted into a negative one when we decided to convert all neutral reviews to negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some positive reviews now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth_sentiment</th>\n",
       "      <th>sentiment_analysis_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4425</th>\n",
       "      <td>1</td>\n",
       "      <td>well crew lucky snuff visit pools spa area spr...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47795</th>\n",
       "      <td>3</td>\n",
       "      <td>long day sight seeing boyfriend needed caffein...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "4425       1  well crew lucky snuff visit pools spa area spr...   \n",
       "47795      3  long day sight seeing boyfriend needed caffein...   \n",
       "\n",
       "      ground_truth_sentiment sentiment_analysis_2  \n",
       "4425                negative             positive  \n",
       "47795               positive             negative  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_2.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'long day sight seeing boyfriend needed caffeine gas failed us exactly location starbucks ended good thing spotted green logo hauled three lanes ended needed cash needed latte needed dinner spotted totes laughed name asian diner saw red sticker approval new saw yelp sticker figured fate tons pan asian fusion options sheet spicy spicy like this place kick love got veggie penang brown rice call hippie tons veggies spicy curry cooked perfectly snap peas eggplant large chunks bell peppers asparagus mixed tofu greatly appreciate fact equal ratio veggies usually asian spots give five million chucks onions leave much else the boyfriend got crispy beef oil tough crispy sweetness good combo spicy curry in bathrooms clean of discount students valid current id food good deal get ever want expand california come santa cruz first line'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_2.text[47795]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review also has a similar story. It tells a story and starts off negative with the couple finding a place, but then diverges.\n",
    "\n",
    "Perhaps a lot of focus is given to words like \"long\" and \"failed\" which push the context to negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Ä gas', 0.07432944994676897),\n",
       " ('Ä spicy', 0.07354530013830957),\n",
       " ('Ä spicy', 0.07160242729595565),\n",
       " ('Ä love', 0.07013955698696211),\n",
       " ('long', 0.06864266490295595),\n",
       " ('Ä food', 0.06822287412818974),\n",
       " ('Ä failed', 0.06698665213891924),\n",
       " ('Ä come', 0.066545486130772),\n",
       " ('Ä current', 0.06334794807115109),\n",
       " ('Ä appreciate', 0.060585563619699516)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_attended_words(incorrect_2.text[47795], model_2, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and Interestingly, it is easy to see why spicy may be a word with a negative connotation. Again, we do see \"failed\"  and \"long\" in the mix, and it makes sense why the model made this decision.\n",
    "\n",
    "\n",
    " Let's look at the last model, model 3 now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50355/1808121878.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  incorrect_3.drop(columns=['sentiment_analysis_1', 'sentiment_analysis_2'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "incorrect_3 = combined[combined['sentiment_analysis_3'] != combined['ground_truth_sentiment']]\n",
    "incorrect_3.drop(columns=['sentiment_analysis_1', 'sentiment_analysis_2'], axis=1, inplace=True)\n",
    "incorrect_3 = incorrect_3.reindex(columns=['label','text', 'ground_truth_sentiment', 'sentiment_analysis_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.10504840387232"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_model_3 = (combined['sentiment_analysis_3'] == combined['ground_truth_sentiment']).mean() * 100\n",
    "accuracy_model_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this model does even better than the last one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth_sentiment</th>\n",
       "      <th>sentiment_analysis_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>recent trip vegas girlfriend decided stop quic...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>customer service best neither bagels no bagels...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>usually come group people service tends good i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>writing first review customer service manageme...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>visiting vegas friend looked see around yelp p...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49928</th>\n",
       "      <td>4</td>\n",
       "      <td>of sweet jesus manger really first thing thoug...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49936</th>\n",
       "      <td>1</td>\n",
       "      <td>good experience tonight make reservations got ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49950</th>\n",
       "      <td>3</td>\n",
       "      <td>noisy crowded unorganized cares vegas food goo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49984</th>\n",
       "      <td>1</td>\n",
       "      <td>salon star rating based salon my friend gift c...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49991</th>\n",
       "      <td>3</td>\n",
       "      <td>wife twice last two weeks four times together ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5947 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "11         1  recent trip vegas girlfriend decided stop quic...   \n",
       "15         1  customer service best neither bagels no bagels...   \n",
       "37         1  usually come group people service tends good i...   \n",
       "42         3  writing first review customer service manageme...   \n",
       "43         1  visiting vegas friend looked see around yelp p...   \n",
       "...      ...                                                ...   \n",
       "49928      4  of sweet jesus manger really first thing thoug...   \n",
       "49936      1  good experience tonight make reservations got ...   \n",
       "49950      3  noisy crowded unorganized cares vegas food goo...   \n",
       "49984      1  salon star rating based salon my friend gift c...   \n",
       "49991      3  wife twice last two weeks four times together ...   \n",
       "\n",
       "      ground_truth_sentiment sentiment_analysis_3  \n",
       "11                  negative             positive  \n",
       "15                  negative             positive  \n",
       "37                  negative             positive  \n",
       "42                  positive             negative  \n",
       "43                  negative             positive  \n",
       "...                      ...                  ...  \n",
       "49928               positive             negative  \n",
       "49936               negative             positive  \n",
       "49950               positive             negative  \n",
       "49984               negative             positive  \n",
       "49991               positive             negative  \n",
       "\n",
       "[5947 rows x 4 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ground_truth_sentiment\n",
       "negative    4254\n",
       "positive    1693\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_3.ground_truth_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model predicted negatives reviews wrongly by a landslide, compared to positives. This is possibly indicative of a stronger pattern.\n",
    "Let's see what goes wrong!\n",
    "\n",
    "<br>\n",
    "\n",
    "We'll again take a random sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth_sentiment</th>\n",
       "      <th>sentiment_analysis_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18519</th>\n",
       "      <td>1</td>\n",
       "      <td>restaurant located shopping center hosting num...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13815</th>\n",
       "      <td>0</td>\n",
       "      <td>bell agio buffet good whelming amount food col...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39981</th>\n",
       "      <td>0</td>\n",
       "      <td>service excellent food salty good asian cafe e...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43368</th>\n",
       "      <td>1</td>\n",
       "      <td>went brazilian bull steakhouse couple years ag...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39265</th>\n",
       "      <td>1</td>\n",
       "      <td>shortage bbl sauce today thanks no barbecue ch...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "18519      1  restaurant located shopping center hosting num...   \n",
       "13815      0  bell agio buffet good whelming amount food col...   \n",
       "39981      0  service excellent food salty good asian cafe e...   \n",
       "43368      1  went brazilian bull steakhouse couple years ag...   \n",
       "39265      1  shortage bbl sauce today thanks no barbecue ch...   \n",
       "\n",
       "      ground_truth_sentiment sentiment_analysis_3  \n",
       "18519               negative             positive  \n",
       "13815               negative             positive  \n",
       "39981               negative             positive  \n",
       "43368               negative             positive  \n",
       "39265               negative             positive  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_3.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'restaurant located shopping center hosting number restaurants including wildly popular firefly shares ownership dragonfly unfortunately asian bistro concept fallen deaf wallets people bar restaurant empty of pm monday evening contrast standing room firefly wife ordered thai beef salad pickled cucumber warm spicy sauce excellent ordered banana leaf salmon steamed miso shiitake mushrooms atlantic salmon good obviously steamed banana leaf cold touch good side dish baby book chop stir fried oyster mushrooms shared'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_3.text[18519]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From first glance, this does not look to be a bad review at all. But the score says otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bell agio buffet good whelming amount food cold greasy tasteless bell agio cafe would highly recommend food buffet personally would rather one well prepared meal eat mediocre food'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_3.text[13815]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review uses verbiage like \"highly recommend\". This possibly could be the reason why it did not detect the overall negative tone with \"cold greasy tasteless\" and \"mediocre\"\n",
    "\n",
    "<br>\n",
    "\n",
    "Let's look at the top attended words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ä mediocre', 0.061311332866167634),\n",
       " ('Ä good', 0.05627847767293439),\n",
       " ('Ä would', 0.05095865168959703),\n",
       " ('Ä tast', 0.049933617669944856),\n",
       " ('Ä one', 0.048325347241612054),\n",
       " ('Ä cafe', 0.04787384716833188),\n",
       " ('Ä personally', 0.04644331020283121),\n",
       " ('eless', 0.04604194138393325),\n",
       " ('Ä cold', 0.04581967607931845),\n",
       " ('Ä food', 0.04438480896786288)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_attended_words(incorrect_3.text[13815], model_3, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that mediocre is the highest attended word. But also that the variance in attention is very spread out, there's not much difference between the attention scores of the first and the 10th word. This means that it may just come down to the number of positive and negative words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how certain the model is while predicting the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9944918155670166}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline_3 = pipeline(model=model_3, task=\"sentiment-analysis\")\n",
    "model_pipeline_3(incorrect_3.text[13815])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, it is very certain that this is a positive review.\n",
    "\n",
    "Perhaps for this specific model or example, the attention score does not necessarily correlate highly? Or maybe it has a very black-and-white view.\n",
    "\n",
    "\n",
    "Let's try testing it with a balanced sentence to see what happens. Facts are usually neutral sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9972461462020874}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline_3(\"The weather today is cloudy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, it gives an overwhelmingly negative score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9927911758422852}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline_3(\"The book is hardcover and has 300 pages.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a very negative response to a very neutral sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9941356182098389}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline_3(\"The car is blue in color.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9979481101036072}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline_3(\"The car is golden in color.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8135625123977661}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline_3(\"The car is red in color.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that simply changing the color changes the output! Maybe because golden is more attributed with \"gold\" and positivity. \n",
    "<br><br>\n",
    "Even red shows a positive sign. Red is a color which is in positive and negative connotations, and we see that the model does give a slightly less polar score (0.81)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We realise from this that the model will jump to extremes and adheres too strongly to certain specific words. Maybe, it's slightly overfit while fine tuning. However, it's still the best model we saw with ~88% accuracy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS6120",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
